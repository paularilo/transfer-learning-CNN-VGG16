{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqNDta-xZ2u4"
   },
   "source": [
    "<b><u>Transfer Learning using CNN: VGG-16</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp81GSFN7uHY"
   },
   "source": [
    "<b><u>Project aim</u></b><br>\n",
    "Use of a pretrained neural network (VGG-16) for a new classification task (flower images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Code structure</u></b>\n",
    "* 1. Set up notebook in Google Colab\n",
    "* 2. Data loading and preprocessing\n",
    "* 3. Load the VGG16 network\n",
    "* 4. Remove the last fully connected layers and set them to be non-trainable\n",
    "* 5. Replace them with new fully-connected layers specific to our problem\n",
    "* 6. Build and compile the chained model\n",
    "* 7. Fitting\n",
    "* 8. Evaluating\n",
    "* 9. Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LR9-yIauZ2vA"
   },
   "source": [
    "# Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21915,
     "status": "ok",
     "timestamp": 1660232102685,
     "user": {
      "displayName": "Bruno Castro Brunckhorst",
      "userId": "00660085536154297213"
     },
     "user_tz": -120
    },
    "id": "_q8uOTzh5vwJ",
    "outputId": "f9f36c20-d391-4114-efdb-cd9a38751f5d"
   },
   "outputs": [],
   "source": [
    "# Mount GDrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1660232103017,
     "user": {
      "displayName": "Bruno Castro Brunckhorst",
      "userId": "00660085536154297213"
     },
     "user_tz": -120
    },
    "id": "7HCO04lsIrcd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/data-transfer-learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-S858KRF7TA"
   },
   "source": [
    "# Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://wagon-public-datasets.s3.amazonaws.com/flowers-dataset.zip`,\n",
    "unzip flowers-dataset.zip`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onPwIzQzF7TE"
   },
   "source": [
    "**Train/Val/Test split**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def load_flowers_data():\n",
    "    data_path = '/content/drive/My Drive/Deep_learning_data/flowers'\n",
    "    classes = {'daisy':0, 'dandelion':1, 'rose':2}\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for (cl, i) in classes.items():\n",
    "        images_path = [elt for elt in os.listdir(os.path.join(data_path, cl)) if elt.find('.jpg')>0]\n",
    "        for img in tqdm(images_path[:300]):\n",
    "            path = os.path.join(data_path, cl, img)\n",
    "            if os.path.exists(path):\n",
    "                image = Image.open(path)\n",
    "                image = image.resize((256, 256))\n",
    "                imgs.append(np.array(image))\n",
    "                labels.append(i)\n",
    "\n",
    "    X = np.array(imgs)\n",
    "    num_classes = len(set(labels))\n",
    "    y = to_categorical(labels, num_classes)\n",
    "\n",
    "    p = np.random.permutation(len(X))\n",
    "    X, y = X[p], y[p]\n",
    "\n",
    "    first_split = int(len(imgs) /6.)\n",
    "    second_split = first_split + int(len(imgs) * 0.2)\n",
    "    X_test, X_val, X_train = X[:first_split], X[first_split:second_split], X[second_split:]\n",
    "    y_test, y_val, y_train = y[:first_split], y[first_split:second_split], y[second_split:]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,15))\n",
    "for i in range(8):\n",
    "    plt.subplot(1,8,i+1)\n",
    "    plt.imshow(X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sx8V9sny7cLP"
   },
   "source": [
    "# Load VGG16 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "def load_model():\n",
    "    model = VGG16(weights=\"imagenet\", include_top=False, input_shape=X_train[0].shape)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3psG3JGF7TO"
   },
   "source": [
    "Look at the architecture of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JtBpKLegF7TO",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deactivate training of VGG-16 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nontrainable_layers(model):\n",
    "    \n",
    "    # first layers untrainable\n",
    "    model.trainable = False    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain pretrained convolutional layers of VGG16 with new dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def add_last_layers(model):\n",
    "    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    base_model = set_nontrainable_layers(model)\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer = layers.Dense(500, activation='relu')\n",
    "    prediction_layer = layers.Dense(3, activation='softmax')\n",
    "    \n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    # $CHALLENGIFY_END\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uqGuxsJF7TR",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "model = add_last_layers(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxXlnPp5F7TR"
   },
   "source": [
    "# Build and compile the model\n",
    "    * Using _adam_ optimizer and `learning_rate=1e-4`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def build_model():\n",
    "    model = load_model()\n",
    "    model = add_last_layers(model)\n",
    "    \n",
    "    opt = optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_input(X_train) \n",
    "X_val = preprocess_input(X_val)\n",
    "X_test = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess our data set with the parameters specific to VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNeJZvtV3YDf",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_train = preprocess_input(X_train) \n",
    "X_val = preprocess_input(X_val)\n",
    "X_test = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T7HvbQfZ2vZ"
   },
   "source": [
    "# Fitting\n",
    "With early stopping criterion (5) on the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grmnNmjeAXcQ",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_accuracy', \n",
    "                   mode = 'max', \n",
    "                   patience = 5, \n",
    "                   verbose = 1, \n",
    "                   restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=50, \n",
    "                    batch_size=16, \n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec_I9JpiAm-W"
   },
   "source": [
    "Plotting accuracy for train set and and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
    "    #ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    #ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESzinGOY6aBc",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3plexlQAtcC"
   },
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ps_9HwUyRVj9",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "res_vgg = model.evaluate(X_test, y_test)\n",
    "\n",
    "test_accuracy_vgg = res_vgg[-1]\n",
    "\n",
    "print(f\"test_accuracy_vgg = {round(test_accuracy_vgg,2)*100} %\")\n",
    "\n",
    "print(f\"test_accuracy = {round(test_accuracy,2)*100} %\")\n",
    "\n",
    "print(f'Chance level: {1./num_classes*100:.1f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5T1KvsGZ2va"
   },
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "    featurewise_std_normalization = False,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    brightness_range = (0.5, 1.),\n",
    "    zoom_range = (0.3, 1.5))\n",
    "\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "model_data_aug = build_model()\n",
    "\n",
    "train_flow = datagen.flow(X_train, y_train, batch_size=16)\n",
    "val_flow = datagen.flow(X_val, y_val, batch_size=16)\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_accuracy', \n",
    "                   mode = 'max', \n",
    "                   patience = 5, \n",
    "                   verbose = 1, \n",
    "                   restore_best_weights = True)\n",
    "\n",
    "history_data_aug = model_data_aug.fit(train_flow,\n",
    "                                      validation_data = val_flow, \n",
    "                                      epochs = 50,\n",
    "                                      callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_vgg = model_data_aug.evaluate(X_test, y_test)\n",
    "\n",
    "test_accuracy_vgg = res_vgg[-1]\n",
    "\n",
    "print(f\"test_accuracy_vgg = {round(test_accuracy_vgg,2)*100} %\")\n",
    "\n",
    "print(f\"test_accuracy = {round(test_accuracy,2)*100} %\")\n",
    "\n",
    "print(f'Chance level: {1./num_classes*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_data_aug)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
